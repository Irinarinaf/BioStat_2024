---
title: "automatization_notebook_03 Garanina"
output: word_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(flextable)
library(ggplot2)
library(ggbeeswarm)
library(RColorBrewer)
library(ggcorrplot2)
library(psych)
library(caret)
library(doParallel)
library("pROC")

#if (!requireNamespace("devtools")) install.packages("devtools")
#devtools::install_github("caijun/ggcorrplot2")
```

# Чтение данных

В вашем варианте нужно использовать датасет framingham.

```{r}
fram <- read_csv("biostat_homework_092024/biostat_homework_092024/data/raw/framingham.csv")
fram |> glimpse()
```

# Выведите общее описание данных

```{r}

fram |> summary()

```

# Очистка данных

1)  Уберите переменные, в которых пропущенных значений больше 20% или уберите субъектов со слишком большим количеством пропущенных значений. Или совместите оба варианта. Напишите обоснование, почему вы выбрали тот или иной вариант:

**Обоснование**: я проверила пациентов на пропуски, оказалось, что на пациента приходится максимум 3 пропуска, что я считаю недостаточно для того чтобы строки удалять. Зависит еще какая переменная пропущена, если бы это был например usubjid, то можно было бы и удалить всю строку. Так же я попробовала удалить переменные в которых пропущенных значений больше 20%, но таких значений не оказалось. По результатам summary больше всего пропущенных значений в глюкозе, но их все равно меньше 10% наблюдений.

2)  Переименуйте переменные в человекочитаемый вид (что делать с пробелами в названиях?);

3)  В соответствии с описанием данных приведите переменные к нужному типу (numeric или factor);

4)  Отсортируйте данные по возрасту по убыванию;

5)  Сохраните в файл outliers.csv субъектов, которые являются выбросами (например, по правилу трёх сигм) — это необязательное задание со звёздочкой;

6)  Присвойте получившийся датасет переменной "cleaned_data".

```{r}
#посчитала количество пропусков на строку
fram_na <- fram %>% mutate(na_count = rowSums(is.na(.))) %>% arrange(desc(na_count)) 
fram_na |> glimpse()
```

```{r}
#отфильтровала переменные с более чем 20% пропусков
fram %>% select(where(~ mean(is.na(.)) <= 0.2))
```

# Сколько осталось переменных?

Все переменные на месте, ни в одной не пропущено более 20

```{r}
#чистка данных
factor_vars <- c("Sex", "Smoker", "Blood Pressure medication", 
                 "Stroke history", "Hypertension history", "Education level",
                 "Diabetes", "Ten year CHD")


cleaned_data <- fram |>
    rename(
        `Sex` = male,
        `Age` = age,
        `Education level` = education,
        `Smoker` = currentSmoker,
        `Sigarettes per day`= cigsPerDay,
        `Blood Pressure medication`= BPMeds,
        `Stroke history` = prevalentStroke,
        `Hypertension history` = prevalentHyp,
        `Diabetes` = diabetes,
        `Cholesterol total` = totChol,
        `Systolic BP` = sysBP,
        `Diastolic BP` = diaBP,
        `Heart rate` = heartRate,
        `Blood glucose` = glucose,
      `Ten year CHD` = TenYearCHD
    ) |>
  mutate(across(all_of(factor_vars), as.factor)) |>
  mutate(Sex = recode(Sex, `0` = "Женский", `1` = "Мужской"),
    across(all_of(c("Smoker", "Blood Pressure medication", 
                 "Stroke history", "Hypertension history",
                 "Diabetes", "Ten year CHD")), ~ recode(.,
    `0` = "Нет",
    `1` = "Да"))) |>
  mutate(id = factor(row_number())) |>
  arrange(desc(Age))
 
  

cleaned_data |> glimpse()
```

# Есть ли в данных идентичные строки?

```{r}

cleaned_data %>%
  group_by_all() %>%
  filter(n() > 1)
```

Выше выводится датасет с дубликатами, он пустой, значит их нет

# Сколько всего переменных с пропущенными значениями в данных и сколько пропущенных точек в каждой такой переменной?

```{r}
#переменные с пропущенными значениями и их количество
cleaned_data %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%   glimpse()

cleaned_data %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>% select_if(~ .[1] > 0) |> length()
```

# Описательные статистики

## Количественные переменные

1)  Рассчитайте для всех количественных переменных для каждой группы (TenYearCHD):

1.1) Количество значений;

1.2) Количество пропущенных значений;

1.3) Среднее;

1.4) Медиану;

1.5) Стандартное отклонение;

1.6) 25% квантиль и 75% квантиль;

1.7) Интерквартильный размах;

1.8) Минимум;

1.9) Максимум;

1.10) 95% ДИ для среднего - задание со звёздочкой.

```{r}
statistics <- list(
      `_Количество субъектов` = ~length(.x)  %>% as.character(),
      `_Количество значений` = ~sum(!is.na(.x))  %>% as.character(),
      `_Количество пропущенных значений` = ~sum(is.na(.x))  %>% as.character(),
      `_Среднее` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", mean(.x, na.rm = TRUE) %>% round(2) %>% format(nsmall = 2, width = 6, justify = "right")),
       `_Медиана` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", median(.x, na.rm = TRUE) %>% round(2) %>% format( nsmall = 2) %>% as.character()),
      `_Стандартное отклонение` = ~ifelse(sum(!is.na(.x)) < 3, "Н/П*", sd(.x, na.rm = TRUE) %>% round(2) %>% format(nsmall = 2, digits = 3) %>% as.character()),
       `_Q1 - Q3` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0(quantile(.x, 0.25, na.rm = TRUE) %>% round(2) %>% format( nsmall = 2), " - ", quantile(.x, 0.75, na.rm = TRUE) %>% round(2) %>% format( nsmall = 2))),
        `_Интерквартильный размах` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", IQR(.x, na.rm = TRUE) %>% round(2) %>% format( nsmall = 2) %>% format( nsmall = 2) %>% as.character()),
      `_Mин. - Mакс.` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0(min(.x, na.rm = TRUE) %>% round(2) %>% format( nsmall = 2), " - ", max(.x, na.rm = TRUE) %>% round(2) %>% format( nsmall = 2))),
     `_95% ДИ для среднего` = ~{
    n <- sum(!is.na(.x))
    if (n < 2) {
      "Н/П*"
    } else {
      mean_val <- mean(.x, na.rm = TRUE)
      stderr <- sd(.x, na.rm = TRUE) / sqrt(n)
      ci_low <- mean_val - 1.96 * stderr
      ci_high <- mean_val + 1.96 * stderr
      paste0(round(ci_low, 2), " - ", round(ci_high, 2))
    }
  }
)

cleaned_data %>% select(`Ten year CHD`, where(is.numeric)) %>%
 group_by (`Ten year CHD`) %>%
summarize(across(where(is.numeric), statistics)) %>%
pivot_longer(!`Ten year CHD`, values_to = "Значение")  %>%
separate(name, into=c("Переменная","Статистика"), sep = "__")%>%
flextable() %>%
autofit %>%
theme_box() %>%
merge_v(c("Ten year CHD", "Переменная")) %>%
align(j = 3, align = "center")
```

## Категориальные переменные

1)  Рассчитайте для всех категориальных переменных для каждой группы (TenYearCHD):

1.1) Абсолютное количество;

1.2) Относительное количество внутри группы;

1.3) 95% ДИ для доли внутри группы - задание со звёздочкой.

```{r}

#отдельно посчитаем частоты и проценты для каждой переменной по группам `Ten year CHD`, для этого сделала функцию, которая считает для одной переменной и потом объединияет все в один датафрейм

results_list <- list()

calculate_ci <- function(count, p, total) {
  stderr <- sqrt(p * (1 - p) / total)
  ci_low <- max(0, p - 1.96 * stderr)
  ci_high <- min(1, p + 1.96 * stderr)
  paste0(round(100 * ci_low, 2), "% - ", round(100 * ci_high, 2), "%")
}

count_percent <- function(data, var) {
cleaned_data %>%
  count(`Ten year CHD`, !!sym(var)) %>%
  group_by(`Ten year CHD`) %>%
  mutate(
    `Количество в группе` = sum(n) %>% as.character(), 
    `Абсолютное количество` = as.character(n),
    `Относительное количество` = paste0((round(n / sum(n)*100, 2)), "%"),
    `95% ДИ для доли` = calculate_ci(n, n / sum(n), sum(n)),
    `Категория` = !!sym(var)
  ) %>%
  ungroup() %>%
 pivot_longer(
      cols = c(`Абсолютное количество`, `Относительное количество`, `95% ДИ для доли`),
      names_to = "Статистика",
      values_to = "Значение"
    )  %>% 
  select (-n, -!!sym(var)) 
 
}

categorical_vars <- names(select(cleaned_data, where(is.factor)))


for (var in categorical_vars) {
  if (var != "id" && var != "Ten year CHD") {
    result <- count_percent(cleaned_data, var)
    results_list[[var]] <- result
  }
}

cat_perc <- bind_rows(results_list, .id = "Переменная")

cat_perc %>%
  mutate(`Категория` = fct_na_value_to_level(`Категория`, level = "Н/C")) %>%
  arrange(`Ten year CHD`,`Переменная`) %>%
  select(`Ten year CHD`, `Количество в группе`, `Переменная`, everything()) %>%
  flextable() %>%
  autofit %>%
  theme_box() %>%
  merge_v(c("Переменная", "Ten year CHD", "Количество в группе", "Категория")) %>%
  align(j = 3, align = "center")
```

```         
```

# Визуализация

## Количественные переменные

1)  Для каждой количественной переменной сделайте боксплоты по группам. Расположите их либо на отдельных рисунках, либо на одном, но читаемо;

2)  Наложите на боксплоты beeplots - задание со звёздочкой.

3)  Раскрасьте боксплоты с помощью библиотеки RColorBrewer.

```{r, fig.width=10, fig.height=10}

data_for_plots<- cleaned_data %>% select(where(is.numeric)) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value")

#из-за очень большого количества наблюдений beeplots получались очень широкие, пришлось выбрать 1% случайных значений для каждой переменной
data_for_plots1<- cleaned_data %>% select(where(is.numeric)) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value") %>%
  group_by(variable) %>%          
  sample_frac(size = 0.01) %>%  
  ungroup()   

colors <- brewer.pal(n = length(unique(data_for_plots$variable)), name = "Set3")

ggplot() +
  geom_boxplot(data = data_for_plots,  aes(x = variable, y = value, fill = variable)) + # Убираем выбросы из боксплотов
  geom_beeswarm(data = data_for_plots1, aes(x = variable, y = value, color = variable), dodge.width = 0.1) + # Добавляем beeplots
  scale_fill_manual(values = colors) + # Раскрашивание боксплотов
  scale_color_manual(values = colors) + # Раскрашивание точек beeplots
  labs(x = "Variable",
       y = "Value") +
  theme_minimal() +
  theme(legend.position = "none")
```

## Категориальные переменные

1)  Сделайте подходящие визуализации категориальных переменных. Обоснуйте, почему выбрали именно этот тип.

```{r}

#я выбрала столбчатый график, показывающий процент категорий цветом. Он хорошо подходит, так как можно компактно сразу показать все переменные.

data_for_plots2 <- cleaned_data %>% select(where(is.factor)) %>% select(-id)  %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value")  %>%
  group_by(`variable`, `value`) %>%
  summarise(count = n(), .groups = 'drop') %>%
  group_by(variable) %>%
  mutate(percent = count / sum(count))

data_for_plots2 |> 
  ggplot( aes(x = variable, y = percent, fill = value)) +
  geom_col() + 
  theme_minimal() +
  coord_flip()
```

# Статистические оценки

## Проверка на нормальность

1)  Оцените каждую переменную на соответствие нормальному распределению с помощью теста Шапиро-Уилка. Какие из переменных являются нормальными и как как вы это поняли?

```{r}

#судя по результатам теста ни одна из количественных переменных не распределена нормально, что неудивительно, так как в датасете больше 4000 наблюдений и даже если распределения визуально близки к нормальным на таком количестве наблюдений тест всегда будет считать распределение отличным от нормального, можно проверить с помощью Q-Q графиков для надежности.
cleaned_data %>%
  select(where(is.numeric)) %>%
  summarise(across(everything(), 
                   ~ shapiro.test(.)$p.value)) %>%  
  pivot_longer(everything(), names_to = "variable", values_to = "p_value") %>%
  mutate(normality = ifelse(p_value > 0.05, "Да", "Нет"))
```

2)  Постройте для каждой количественной переменной QQ-плот. Отличаются ли выводы от теста Шапиро-Уилка? Какой метод вы бы предпочли и почему?

```{r, fig.width=7, fig.height=7}

#Q-Q графики подтверждают результаты теста, хотя график для возраста выглдят довольно близко к нормальному, но хвосты выборки явно не соответвуют, остальные распределения судя по графикам перекошены в одну сторону. В случае если много переменных или нужно автоматически настроить проверку нормальности - я бы предпочла тест графическому методу, но если переменных мало, то лучше использовать оба метода.

df_long <- cleaned_data  %>%
  select(where(is.numeric)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "value")

ggplot(df_long, aes(sample = value)) +
  stat_qq() +  # Добавляем Q-Q plot
  stat_qq_line() +  # Добавляем линию для Q-Q plot
  facet_wrap(~ variable, scales = "free") +  # Фасеты для каждой переменной
  theme_minimal() +  # Стиль оформления
  labs(title = "Q-Q Plot для каждой переменной", 
       x = "Теоретические квантили", 
       y = "Наблюдаемые квантили")
```

3)  Ниже напишите, какие ещё методы проверки на нормальность вы знаете и какие у них есть ограничения.

Можно визуально сравнить гистограмму данных с наложенной нормальной кривой, этот метод проще всего интерпретировать, но его результат зависит от размера бина и его невозможно автоматизировать. Еще тест Колмогорова-Смирнова, но точной разницы с тестом Шапиро-Уилка я не знаю, оба широко применяются, но думаю, что оба на таких огромных выборках будут слишком чувствительны и не покажут нормальность.

## Сравнение групп

1)  Сравните группы (переменная **TenYearCHD**) по каждой переменной (как количественной, так и категориальной). Для каждой переменной выберите нужный критерий и кратко обоснуйте его выбор в комментариях.

```{r}

#для сравнения количественных переменных я делаю сначала тест на нормальность, по результатам которого определяется делать t-test или тест Манна-Уитни. Для категориальных я выбрала точный тест Фишера, поскольку он применим для ситуаций когда в одной из категорий мало наблюдений, на случай если он не может быть выполнен, например, из-за недостатка памяти или слишком большого количества категорий, выполняется хи-квадрат тест.

# 1. Проверка нормальности количественных переменных
normality_results <- cleaned_data %>%
  select(where(is.numeric)) %>%
  summarise(across(everything(), ~ shapiro.test(.)$p.value)) %>%  
  pivot_longer(everything(), names_to = "variable", values_to = "p_value") %>%
  mutate(normality = ifelse(p_value > 0.05, "Да", "Нет"))

# 2. Функция для автоматического выбора теста и проведения анализа
comparison_results <- map_dfr(names(cleaned_data %>% select(-id)), function(var) {
  var_quoted <- paste0("`", var, "`")
  if (var != "Ten year CHD") {
    if (is.numeric(cleaned_data[[var]])) {
      normality <- normality_results %>%
        filter(variable == var) %>%
        pull(normality)
      
      test_result <- if (normality == "Да") {
        t_test <- t.test(as.formula(paste(var_quoted, "~ `Ten year CHD`")), data = cleaned_data)
        tibble(variable = var, test = "t-test", p_value = t_test$p.value)
      } else {
        wilcox_test <- wilcox.test(as.formula(paste(var_quoted, "~ `Ten year CHD`")), data = cleaned_data)
        tibble(variable = var, test = "Mann-Whitney U", p_value = wilcox_test$p.value)
      }
    } else if (is.factor(cleaned_data[[var]])) {
      tryCatch({
        fisher_test <- fisher.test(table(cleaned_data[[var]], cleaned_data$`Ten year CHD`))
        tibble(variable = var, test = "Fisher's Exact", p_value = fisher_test$p.value)
      }, error = function(e) {
        chi_test <- chisq.test(table(cleaned_data[[var]], cleaned_data$`Ten year CHD`))
        tibble(variable = var, test = "Chi-squared", p_value = chi_test$p.value)
      })
    } else {
      NULL
    }
  } else {
    NULL 
  }
})

# Объединяем результаты нормальности и тестов
final_results <- normality_results %>%
  select(-p_value) %>%
  right_join(comparison_results, by = "variable") %>%
  mutate(`p_value` = ifelse(p_value < 0.001, "< 0.001", formatC(p_value, format = "f", digits = 3)))

final_results
```

# Далее идут **необязательные** дополнительные задания, которые могут принести вам дополнительные баллы в том числе в случае ошибок в предыдущих

## Корреляционный анализ

1)  Создайте корреляционную матрицу с визуализацией и поправкой на множественные сравнения. Объясните, когда лучше использовать корреляционные матрицы и в чём минусы и плюсы корреляционных исследований.

```{r, fig.width=7, fig.height=7}

#команда для установки пакета ggcorrplot2 с github есть в первом чанке
num_data <- cleaned_data %>%
  select(where(is.numeric))

ct <- corr.test(num_data, adjust = "holm")
corr <- ct$r
p.mat <- ct$p


ggcorrplot.mixed(corr, upper = "ellipse", lower = "number", p.mat = p.mat, 
                 insig = "label_sig", sig.lvl = c(0.05, 0.01, 0.001))

#корреляционные матрицы удобно использовать когда есть много переменных, например в случае выбора модели для регрессии. В данном случае получилось интересно, что не смотря на значимость почти всех попарных сравнений только одна корреляция имеет высокий коэффициент корреляции, то есть при таком анализе важно учитывать размер коэффициента и p-value. На этом графике так же можно понять какую форму имеет график взаимосвязи переменных, что подтвержает незначимость корреляций. Похоже, что из-за большого размера выборки мы видим ложноположительные результаты теста, даже не смотря на поправку на множественное сравнение.
```

## Моделирование

1)  Постройте регрессионную модель для переменной **TenYearCHD**. Опишите процесс построения

    ```{r}
    #исключила диастолическое давление из-за высокой кореляции с систолическим
    cleaned_data_bp <- cleaned_data %>% select(-`Diastolic BP`)
    get_mode <- function(v) {
      uniq_v <- unique(v)
      uniq_v[which.max(tabulate(match(v, uniq_v)))]
    }
    #заменила NA на среднее для количественных переменных и медиану для факторных
    cleaned_data_bp_na1 <- cleaned_data_bp %>%
      mutate(across(where(is.numeric), ~ replace_na(., mean(., na.rm = TRUE))))

    cleaned_data_bp_na2 <- cleaned_data_bp_na1 %>%
      mutate(across(where(is.factor), ~ replace_na(., as.factor(get_mode(.)))))

    #логистическая модель, включающая все переменные, кроме id
    simple_model <- glm(`Ten year CHD` ~ . - id, 
                        data = cleaned_data_bp_na2, 
                        family = binomial)

    # Вывод результатов модели
    summary(simple_model)
    ```

```{r}
predicted_probs <- predict(simple_model, type = "response")

# ROC-анализ, где `Ten year CHD` — фактические значения
roc_curve <- roc(cleaned_data_bp_na2$`Ten year CHD`, predicted_probs)

# Печать значения AUC
auc_value <- auc(roc_curve)
print(auc_value)

# Построение ROC-кривой
plot(roc_curve, col = "blue", main = "ROC Curve for Simple Model")
```

```{r}
significant_vars <- names(coef(simple_model))[summary(simple_model)$coefficients[, 4] < 0.05]
significant_vars
```

```{r}

#выбрала только те переменные, у которых значимые коэффициенты, автоматически не получилось, так как сложно избавиться от уровней у категориальных переменных в названии
sig_model <- glm(`Ten year CHD` ~ Sex + Age + `Sigarettes per day` + `Stroke history` +  `Systolic BP` + `Blood glucose`,                                           data = cleaned_data_bp_na2, 
                    family = binomial)

summary(sig_model)
```

```{r}
#проверила лучше ли эта модель исходной, значительной разницы по AUC нет
predicted_probs <- predict(sig_model, type = "response")

# ROC-анализ, где `Ten year CHD` — фактические значения
roc_curve <- roc(cleaned_data_bp_na2$`Ten year CHD`, predicted_probs)

# Печать значения AUC
auc_value <- auc(roc_curve)
print(auc_value)

# Построение ROC-кривой
plot(roc_curve, col = "blue", main = "ROC Curve for Sig. Model")
```
